###############################
# Kafka Connect Distributed Worker
###############################

# Bootstrap servers Kafka
bootstrap.servers=${KAFKA_BOOTSTRAP_SERVERS}

# Worker configuration
group.id=connect-cluster
key.converter=org.apache.kafka.connect.json.JsonConverter
key.converter.schemas.enable=false
value.converter=org.apache.kafka.connect.json.JsonConverter
value.converter.schemas.enable=false

# Offset storage (persisted in Kafka)
offset.storage.topic=connect-offsets
offset.storage.replication.factor=1
offset.flush.interval.ms=10000

# Config storage (persisted in Kafka)
config.storage.topic=connect-configs
config.storage.replication.factor=1

# Status storage (persisted in Kafka)
status.storage.topic=connect-status
status.storage.replication.factor=1

# Rest API worker
rest.port=8083
rest.advertised.host.name=${CONNECT_HOST}

# Plugins / connectors path
plugin.path=/usr/share/java

# Internal worker threads
tasks.max=1

# Error handling
errors.log.enable=true
errors.log.include.messages=true
errors.tolerance=all

# Retry & backoff (for failed tasks)
retry.backoff.ms=5000
max.retries=10

# Heartbeat
heartbeat.interval.ms=10000

# Security (SASL/SSL if needed)
# security.protocol=SASL_SSL
# sasl.mechanism=PLAIN
# sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="user" password="password";

# Confluent-specific (DLQ support)
errors.deadletterqueue.topic.name=connect-dlq
errors.deadletterqueue.context.headers.enable=true

# Logging
log4j.rootLogger=INFO, stdout
log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=[%d] %p %m (%c)%n
