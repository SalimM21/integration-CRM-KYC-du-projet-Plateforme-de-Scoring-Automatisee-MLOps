# ğŸ¦ Plateforme de Scoring AutomatisÃ©e â€” Ingestion & IntÃ©gration CRM

Ce module fait partie du projet **File Rouge â€” Plateforme de Scoring MLOps Complet**.  
Il gÃ¨re la **collecte**, la **validation**, et la **centralisation** des donnÃ©es issues de plusieurs sources :
- CRM (clients, prospects)
- Transactions
- API externes (KYC, AML)
- SystÃ¨mes internes (RH, distribution)

---

## ğŸš€ Objectifs

- Centraliser les donnÃ©es multi-sources en temps rÃ©el (Kafka + Connect)
- Garantir la qualitÃ© et la traÃ§abilitÃ© (schemas Avro / JSON)
- GÃ©rer les erreurs et retries via DLQ
- Alimenter le Data Lake (MinIO / Delta Lake)
- PrÃ©parer les donnÃ©es pour le scoring et la dÃ©tection de fraude

---

## ğŸ—ï¸ Architecture Technique

```mermaid
flowchart LR
    %% ğŸ§© Architecture globale Data Ingestion

    subgraph CRM
        A1[Base CRM : Postgres ou MySQL]
    end

    subgraph KafkaCluster["Kafka Cluster - Strimzi"]
        A2[Kafka Connect : Debezium + JDBC Source]
        A3[Kafka Topics : crm_customers, transactions]
        A4[S3 Sink â†’ MinIO]
        A5[JDBC Sink â†’ PostgreSQL DWH]
    end

    subgraph SparkLayer["Spark Streaming Layer"]
        B1[PySpark Structured Streaming]
        B2[Validation JSON Schema]
        B3[Delta Lake Writer]
    end

    subgraph AirflowOrch["Airflow Orchestration"]
        C1[DAG Ingestion CRM]
        C2[DAG Validation et DLQ]
        C3[DAG KYC Batch ou API]
    end

    subgraph VaultSecrets["Vault / K8s Secrets"]
        S1[Credentials CRM et API]
        S2[Kafka Connect Secrets]
    end

    subgraph DataLake["Data Lake / Gouvernance"]
        D1[MinIO : Raw - Bronze]
        D2[Delta Lake : Silver - Gold]
        D3[PostgreSQL DWH]
    end

    subgraph Monitoring["Monitoring et Logging"]
        M1[Prometheus / Grafana]
        M2[ELK / Evidently AI]
    end

    %% ğŸ”— Connexions principales
    A1 --> A2
    A2 --> A3
    A3 -->|Avro Messages| B1
    B1 --> B2 --> B3 --> D2
    A4 --> D1
    A5 --> D3
    B1 --> C1
    C1 --> C2
    C3 --> D2
    S1 --> A2
    S2 --> C1
    B3 --> M1
    B3 --> M2
```
## ğŸ“‚ Structure des dossiers

```
ingestion/
â”œâ”€â”€ kafka/
â”‚   â”œâ”€â”€ connect/
â”‚   â”‚   â”œâ”€â”€ connectors/
â”‚   â”‚   â”‚   â”œâ”€â”€ debezium-crm-source.json        # Connecteur Debezium pour CRM (Postgres/MySQL)
â”‚   â”‚   â”‚   â”œâ”€â”€ jdbc-sink-dwh.json              # Sink JDBC vers Postgres ou Data Warehouse
â”‚   â”‚   â”‚   â”œâ”€â”€ s3-sink-minio.json              # Sink vers MinIO/S3
â”‚   â”‚   â”‚   â”œâ”€â”€ kyc-api-source.json             # (Optionnel) Connecteur REST API pour KYC
â”‚   â”‚   â””â”€â”€ config/
â”‚   â”‚       â”œâ”€â”€ connect-distributed.properties  # Configuration principale du worker Connect
â”‚   â”‚       â”œâ”€â”€ secrets.env                     # Variables secrÃ¨tes (vault ou k8s secrets)
â”‚   â”‚       â””â”€â”€ log4j.properties
â”‚   â”œâ”€â”€ topics/
â”‚   â”‚   â”œâ”€â”€ crm_customers.avsc                  # SchÃ©ma Avro pour les donnÃ©es CRM
â”‚   â”‚   â”œâ”€â”€ transactions.avsc                   # SchÃ©ma Avro pour les transactions
â”‚   â”‚   â”œâ”€â”€ kyc_response_schema.json            # SchÃ©ma JSON pour la validation KYC
â”‚   â”‚   â””â”€â”€ topic_config.yaml                   # Config topics (partitions, retention, DLQ)
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ create_topics.sh                    # Script dâ€™automatisation crÃ©ation topics
â”‚   â”‚   â”œâ”€â”€ deploy_connectors.sh                # Script curl vers API Kafka Connect
â”‚   â”‚   â””â”€â”€ test_ingestion.py                   # Test dâ€™ingestion (latence, volumÃ©trie)
â”‚   â””â”€â”€ manifests/
â”‚       â”œâ”€â”€ kafka-cluster.yaml                  # CRD Strimzi Kafka (avec persistence + secrets)
â”‚       â”œâ”€â”€ kafka-connect.yaml                  # DÃ©ploiement Connect (Strimzi)
â”‚       â”œâ”€â”€ secret-kafka.yaml                   # Secret Kubernetes / Vault reference
â”‚       â”œâ”€â”€ k8s-pvc.yaml                        # Volumes persistants
â”‚       â””â”€â”€ vault-policy.hcl                    # Policy HashiCorp Vault pour accÃ¨s secrets
â”‚
â”œâ”€â”€ spark/
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”‚   â”œâ”€â”€ streaming_kafka_to_delta.ipynb      # Notebook PySpark (Kafka â†’ Delta)
â”‚   â”‚   â”œâ”€â”€ validate_json_schema.ipynb          # Validation JSON schema des messages
â”‚   â”‚   â”œâ”€â”€ enrich_kyc_batch.ipynb              # IntÃ©gration API KYC et stockage
â”‚   â”‚   â””â”€â”€ monitoring_drift.ipynb              # (Optionnel) Monitoring qualitÃ© data
â”‚   â”œâ”€â”€ jobs/
â”‚   â”‚   â”œâ”€â”€ kafka_streaming_job.py              # Version exÃ©cutable du notebook
â”‚   â”‚   â””â”€â”€ retry_dlq_handler.py                # Gestion retry/DLQ
â”‚   â”œâ”€â”€ configs/
â”‚   â”‚   â”œâ”€â”€ spark_config.yaml                   # ParamÃ¨tres SparkSession
â”‚   â”‚   â””â”€â”€ delta_config.yaml                   # ParamÃ¨tres Delta Lake
â”‚   â””â”€â”€ tests/
â”‚       â”œâ”€â”€ test_streaming_ingestion.py         # Test de flux Kafka -> Delta
â”‚       â””â”€â”€ test_data_validation.py             # Validation JSON schema
â”‚
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â”œâ”€â”€ dag_ingestion_crm.py                # DAG orchestration ingestion CRM
â”‚   â”‚   â”œâ”€â”€ dag_ingestion_kyc.py                # DAG batch KYC
â”‚   â”‚   â””â”€â”€ dag_monitoring_dlq.py               # DAG supervision des messages en erreur
â”‚   â””â”€â”€ plugins/
â”‚       â”œâ”€â”€ operators/
â”‚       â”‚   â”œâ”€â”€ kafka_operator.py
â”‚       â”‚   â”œâ”€â”€ spark_submit_operator.py
â”‚       â”‚   â””â”€â”€ vault_secret_operator.py
â”‚       â””â”€â”€ sensors/
â”‚           â””â”€â”€ kafka_topic_sensor.py
â”‚
â””â”€â”€ validation/
    â”œâ”€â”€ schemas/
    â”‚   â”œâ”€â”€ crm_schema.json                     # SchÃ©ma de validation CRM
    â”‚   â”œâ”€â”€ transaction_schema.json             # SchÃ©ma de validation transaction
    â”‚   â””â”€â”€ kyc_schema.json                     # SchÃ©ma de validation KYC
    â”œâ”€â”€ utils/
    â”‚   â”œâ”€â”€ schema_validator.py                 # Utilitaire de validation JSON/Avro
    â”‚   â”œâ”€â”€ dlq_handler.py                      # Gestion DLQ automatique
    â”‚   â””â”€â”€ retry_manager.py                    # MÃ©canisme de retry
    â””â”€â”€ tests/
        â”œâ”€â”€ test_schema_validator.py
        â””â”€â”€ test_dlq_retry.py

```
---
## âš™ï¸ DÃ©ploiement (mode dev / demo)
1ï¸âƒ£ **PrÃ©requis**

- Kubernetes 1.25+
- Helm 3+
- Strimzi Operator installÃ©
- Vault / K8s Secrets activÃ©s
- MinIO, PostgreSQL dÃ©ployÃ©s

2ï¸âƒ£ **DÃ©ploiement avec Helm**

```bash
helm install kafka strimzi/strimzi-kafka-operator -f kafka/values.yaml
kubectl apply -f kafka/manifests/kafka-cluster.yaml
kubectl apply -f kafka/manifests/kafka-connect.yaml
```

3ï¸âƒ£ **DÃ©ploiement des connecteurs**

```bash
cd ingestion/kafka/scripts/
bash deploy_connectors.sh
```
## âœ… Tests

- ``test_streaming_ingestion.py`` : vÃ©rifie la lecture Kafka â†’ Delta
- ``test_data_validation.py`` : valide les schÃ©mas Avro/JSON
- ``test_dlq_retry.py`` : teste le mÃ©canisme de retry/DLQ

## ğŸ”’ SÃ©curitÃ© & Secrets

- Les credentials (DB, API, Kafka Connect) sont stockÃ©s dans :
  - **HashiCorp Vault** (``vault-policy.hcl``)
  - **Kubernetes Secrets** (``secret-kafka.yaml``)
- Les connecteurs rÃ©fÃ©rencent les secrets via ``valueFrom.secretKeyRef``.

## ğŸ“Š Monitoring

- **Prometheus + Grafana** â†’ mÃ©triques Kafka / Spark / Airflow
- **Evidently AI** â†’ drift de donnÃ©es et qualitÃ© des features
- **ELK Stack** â†’ logs Kafka Connect et Airflow

